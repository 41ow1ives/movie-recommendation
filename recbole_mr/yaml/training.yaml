# training settings
epochs: 100
train_batch_size: 1024
learner: adam
learning_rate: 0.001
train_neg_sample_args: 
  dynamic: true
eval_step: 1
stopping_step: 10
weight_decay: 0.1